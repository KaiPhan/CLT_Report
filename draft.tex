\section*{Draft ideas}
\subsection{Abstract}
\begin{itemize}
    \item What is the CLT? Why is formal verification important?
    \item What limitations or gaps does this work address?
    \item Briefly summarize the methods, results, and significance.
\end{itemize}
\section{Introduction}
\textbf{Purpose:} Set the stage for this thesis, establish its relevance, and provide an overview of the challenges and contributions.

\subsection{Background of the Central Limit Theorem (CLT)}
\begin{itemize}
    \item Briefly describe the CLT's significance in probability theory and its foundational role in various fields.
    \item Highlight the diversity of proofs for the CLT, focusing on Lyapunov’s direction as a generalization of the i.i.d. case.
\end{itemize}

\subsection{Formal Verification of Mathematical Theorems}   
\begin{itemize}
    \item Discuss the importance of formalizing theorems like the CLT for computational mathematics.
    \item Introduce HOL4 and its potential for advancing probability theory through rigorous formalization.
\end{itemize}

\subsection{Challenges and Motivation}
\begin{itemize}
    \item Outline the unique challenges of formalizing Lyapunov’s approach in HOL4:
    \item HOL4 lacks a robust library for complex analysis and probability.
    \item The proof depends on Taylor expansions, Big-O notation, and Lyapunov’s inequality, which needed to be formalized from scratch.
    \item Describe the failed attempt to use moment generating functions (MGFs) and how it inspired the shift to Lyapunov’s approach.
\end{itemize}    
   
\subsection{Thesis Contributions}
\begin{itemize}
    \item Summarize key contributions:
    \begin{enumerate}
        \item Formalization of Lyapunov’s inequality in HOL4.
        \item Development of supporting libraries for Taylor expansions, Big-O notation, and moment analysis.
        \item Complete formalization of the CLT based on Lyapunov’s theorem.
    \end{enumerate}
\end{itemize}

\section{Background and Related Work}
\textbf{Purpose:} Position this work in the context of previous efforts and provide foundational concepts.
\subsection{Overview of the Central Limit Theorem}
\begin{itemize}
    \item Explain the statement of the CLT and its generalizations (e.g., Lyapunov’s and Lindeberg’s approaches).
    \item Focus on Lyapunov’s version as the basis of this proof:
    
     \begin{equation}
     \text{If } \frac{\Gamma_n}{s_n^3} \to 0 \text{ as } \space \space n \to \infty, 
     \end{equation}
     then 
     \[
     \frac{S_n}{s_n} \xrightarrow{d} \Phi. 
     \] 
     Define key terms: \( \Gamma_n, s_n, S_n \), and Lyapunov’s condition.
\end{itemize}
   
\subsection{Formal Proof Assistants in Probability Theory}
\begin{itemize}
    \item Discuss Isabelle/HOL and its use of characteristic functions to prove the CLT (mention Luke Serafin’s work briefly here).
    \item Highlight HOL4’s potential and this thesis's motivation to enrich its probability theory libraries.
\end{itemize}

\subsection{Lyapunov’s Direction and Proof Techniques}   
\begin{itemize}
    \item Provide an informal overview of Lyapunov’s proof steps:
    \begin{itemize}
        \item Construction of normal approximations (\( Y_j \)).
        \item Use of Taylor expansions to bound differences.
        \item Application of Lyapunov’s inequality to ensure convergence.
    \end{itemize}
     
   \item Contrast Lyapunov’s approach with other CLT proofs, emphasizing why it’s more suitable for HOL4’s existing framework.
\end{itemize}
   
\section{The Formalization Process}
\textbf{Purpose: Detail the technical challenges and solutions in formalizing Lyapunov’s proof in HOL4.}
\subsection{Overview of Lyapunov’s Proof Structure}
\begin{itemize}
    \item Provide a roadmap of the proof components you formalized:
    \begin{enumerate}
        \item Taylor expansions and approximation of test functions.
        \item Telescoping sums and bounding higher-order moments.
        \item Lyapunov’s inequality and its application to ensure convergence.
    \end{enumerate}
\end{itemize}

\subsection{Formalizing the Supporting Theorems in HOL4}
\begin{itemize}
    \item Taylor Expansion
    \item Big-O Notation
    \item Lyapunov’s Inequality
\end{itemize}

\subsection{Technical Challenges and Innovations}
\begin{itemize}
    \item Share how HOL4’s lack of complex analysis tools required alternative approaches (e.g., using Lyapunov’s proof instead of characteristic functions).
    \item ...
\end{itemize}
   
\section{The Formal Proof of the CLT in HOL4}
\textbf{Purpose:} Present the completed proof and validate its correctness.
\subsection{Step-by-Step Proof}
\begin{itemize}
    \item Present the formalized proof of Lyapunov’s theorem in HOL4.
    \item Break it into logical steps, mirroring the informal proof:
    \begin{enumerate}
        \item Setup and normalization of \( S_n \).
        \item Construction of \( Z_j \) and comparison with \( X_j \).
        \item Application of Taylor expansions and bounding error terms.
        \item Application of Lyapunov’s inequality to complete the proof.
    \end{enumerate}
\end{itemize}

\subsection{Validation and Soundness}  
\begin{itemize}
    \item Discuss how HOL4 ensures the proof’s correctness and soundness.
    \item Highlight key intermediate results that confirm the integrity of this thesis's approach.
\end{itemize}   
 
\section{Results and Comparisons}
\textbf{Purpose:} Showcase the impact of this work and compare it to related efforts.
\subsection{Achievements in HOL4}
\begin{itemize}
    \item Summarize the completed formalization of Lyapunov’s CLT proof.
    \item  Highlight the additional libraries (e.g., Taylor expansions, Big-O notation) and their potential for future work.
\end{itemize}
 
\subsection{Comparison with Isabelle/HOL}
\begin{itemize}
    \item Briefly compare this work with Luke Serafin’s formalization of the CLT in Isabelle:
    \begin{itemize}
        \item HOL4 uses Lyapunov’s approach instead of characteristic functions.
        \item Discuss the trade-offs: HOL4’s modularity and flexibility versus Isabelle’s existing tools for complex analysis.
    \end{itemize}
\end{itemize}

\section{Conclusion}
\textbf{Purpose:} Reflect on the thesis’s contributions and look ahead.
\subsection{Summary of Contributions}
Restate achievements:
\begin{enumerate}
     \item Formalized Lyapunov’s theorem and the CLT in HOL4.
     \item  Extended HOL4’s libraries for probability theory.
     \item  Overcame challenges related to HOL4’s lack of complex analysis tools.
\end{enumerate}

Also, discuss the significance of enriching HOL4 for future formalizations in probability and functional analysis.

\subsection{Future Work}
Suggest potential extensions, such as:
\begin{itemize}
    \item Formalizing multivariate versions of the CLT.
    \item Extending HOL4’s libraries for advanced probabilistic theorems.
\end{itemize}

\subsection{Appendices and Supplementary Material}
Code listings, etc.

\newpage
\subsection{The proof of Central Limit Theorem}
\subsubsection{Informal Proof without introducing Y ((the replacement Gaussian random variables))}
\begin{itemize}
        \item[] \( \mathbb{E}[X_j] = 0 \), 
        \item[] \( \text{Var}(X_j) = \sigma_j^2 \) (finite variances, \( \sigma_j^2 < \infty \)),
        \item[] \( \mathbb{E}[|X_j|^3] = \gamma_j \) (finite third moments, \( \gamma_j < \infty \)).
    \end{itemize}

Define:
        \begin{itemize}
            \item[] \( S_n = \sum_{j=1}^n X_j \),
            \item[] \( s_n^2 = \sum_{j=1}^n \sigma_j^2 \) (total variance),
            \item[] \( \Gamma_n = \sum_{j=1}^n \gamma_j \) (total third moment).
\end{itemize}

Statement:

    If 
    \[
   \frac{\Gamma_n}{s_n^3} \to 0 \quad \text{as } n \to \infty.
   \]
   then 
   \[
   \frac{S_n}{s_n} \xrightarrow{d} \Phi
   \]
   where \( \Phi\) denotes the standard normal distribution \( \mathcal{N}(0,1) \).

Let $\boldsymbol{Z_n = S_n / s_n }$, to prove $\boldsymbol{Z_n \xrightarrow{d} \mathcal{N}(0,1)}$, it suffices to show that for any bounded, continuous test function \( f \in C_b^3(\mathbb{R}) \) (bounded continuous functions with three bounded derivatives):
\[
\mathbb{E}[f(Z_n)] \to \mathbb{E}[f(\mathcal{N})],
\]

Using Taylor’s theorem, we expand \( f(Z_n) \) around \( 0 \):
\[
f(Z_n) = f(0) + f'(0)Z_n + \frac{f''(0)}{2}Z_n^2 + R(Z_n),
\]
where \( R(Z_n) \) is the remainder:
\[
R(Z_n) = \frac{f^{(3)}(\xi)}{6}Z_n^3,
\]
for some \( \xi \) between \( 0 \) and \( Z_n \).

Taking expectations:
\[
\mathbb{E}[f(Z_n)] = f(0) + f'(0)\mathbb{E}[Z_n] + \frac{f''(0)}{2}\mathbb{E}[Z_n^2] + \mathbb{E}[R(Z_n)].
\]

Similarly, for \( \mathcal{N}(0,1) \), we expand \( f(\mathcal{N}) \):
\[
\mathbb{E}[f(\mathcal{N})] = f(0) + f'(0)\mathbb{E}[\mathcal{N}] + \frac{f''(0)}{2}\mathbb{E}[\mathcal{N}^2] + \mathbb{E}[R(\mathcal{N})].
\]

Thus, the difference becomes:
\[
\mathbb{E}[f(Z_n)] - \mathbb{E}[f(\mathcal{N})] = \underbrace{f'(0) (\mathbb{E}[Z_n] - \mathbb{E}[\mathcal{N}])}_{(a)} + \underbrace{\frac{f''(0)}{2} (\mathbb{E}[Z_n^2] - \mathbb{E}[\mathcal{N}^2])}_{(b)} + \underbrace{(\mathbb{E}[R(Z_n)] - \mathbb{E}[R(\mathcal{N})])}_{(c)}.
\]

By analyzing each term, we have:

\textbf{(a)} $\boldsymbol{f'(0) (\mathbb{E}[Z_n] - \mathbb{E}[\mathcal{N}])}$
\begin{itemize}
    \item By assumption, \( \mathbb{E}[X_j] = 0 \), so \( \mathbb{E}[S_n] = 0 \), and:
  \[
  \mathbb{E}[Z_n] = \frac{\mathbb{E}[S_n]}{s_n} = 0.
  \]
  \item For \(\mathcal{N}(0, 1)\), \( \mathbb{E}[\mathcal{N}] = 0 \).
\end{itemize}
Therefore:
  \[
  f'(0) (\mathbb{E}[Z_n] - \mathbb{E}[\mathcal{N}]) = 0.
  \]

(b) $\boldsymbol{\frac{f''(0)}{2} (\mathbb{E}[Z_n^2] - \mathbb{E}[\mathcal{N}^2])}$
\begin{itemize}
    \item The variance of \( S_n \) is \( s_n^2 = \sum_{j=1}^n \sigma_j^2 \), so:
  \[
  \text{Var}(Z_n) = \frac{\text{Var}(S_n)}{s_n^2} = \frac{s_n^2}{s_n^2} = 1.
  \]
    \item Thus:
  \[
  \mathbb{E}[Z_n^2] = 1.
  \]
    \item For \( \mathcal{N}(0,1) \), \( \mathbb{E}[\mathcal{N}^2] = 1 \).
\end{itemize}
Therefore:
  \[
  \frac{f''(0)}{2} (\mathbb{E}[Z_n^2] - \mathbb{E}[\mathcal{N}^2]) = 0.
  \]

(c) $\boldsymbol{\mathbb{E}[R(Z_n)] - \mathbb{E}[R(\mathcal{N})]}$

By Taylor's theorem, We have:
\[
\mathbb{E}[R(Z_n)] \leq \frac{M}{6} \mathbb{E}[Z_n^3], 
\]
and

\[
\mathbb{E}[R(\mathcal{N})] \leq \frac{M}{6} \mathbb{E}[\mathcal{N}^3]
\]

where \( M = \sup_{x \in \mathbb{R}} |f^{(3)}(x)| \) is the maximum bound on the third derivative of \( f \).

Thus, 
\begin{equation}{\label{final_eq}}
    \left| \mathbb{E}[R(Z_n)] - \mathbb{E}[R(\mathcal{N})] \right| \leq \frac{M}{6} \left|\mathbb{E}[Z_n^3] - \mathbb{E}[\mathcal{N}^3] \right| 
\end{equation}


\textbf{For} $\boldsymbol{Z_n}$:

The normalized third moment of \( Z_n = S_n / s_n \) is:
\begin{equation}{\label{Z_cube}}
    \mathbb{E}[Z_n^3] = \frac{\mathbb{E}[|S_n|^3]}{s_n^3}.
\end{equation}

Using Triangle inequality for sums, which states:
\begin{equation}{\label{lya_Z}}
    \mathbb{E}[|S_n|^3] = \mathbb{E}\left[\left| \sum_{j=1}^n X_j \right|^3\right] \leq \sum_{j=1}^n \mathbb{E}[|X_j|^3],
\end{equation}

Combining \eqref{Z_cube} and \eqref{lya_Z} we get:
\[
\mathbb{E}[|Z_n|^3] \leq \frac{\sum_{j=1}^n \gamma_j}{s_n^3},
\]
where \( \gamma_j = \mathbb{E}[|X_j|^3] \).

Thus:
\[
\mathbb{E}[R(Z_n)] \leq \frac{M}{6} \frac{\sum_{j=1}^n \gamma_j}{s_n^3}.
\]



\textbf{For} $\boldsymbol{\mathcal{N}(0,1)}$:
The third moment of \( \mathcal{N} \) is constant:
\begin{equation}{\label{third_moment}}
    \mathbb{E}[\mathcal{N}^3] = 0,
\end{equation}

To prove \eqref{third_moment}, we use moment generating function (MGF). The moment generating function (MGF) of a random variable \( X \) is defined as:
\[
M_X(t) = \mathbb{E}[e^{tX}].
\]

For \( X \sim N(0, 1) \), the MGF is known to be:
\[
M_X(t) = e^{t^2 / 2}.
\]
This follows from integrating the product of \( e^{tx} \) and the PDF of \( N(0, 1) \):
\[
M_X(t) = \int_{-\infty}^\infty e^{tx} \frac{1}{\sqrt{2\pi}} e^{-x^2 / 2} \, dx = e^{t^2 / 2}.
\]

Then, third derivative:
   \[
   M_X^{(3)}(t) = \frac{d}{dt} \left( e^{t^2 / 2} + t^2 e^{t^2 / 2} \right).
   \]
   Differentiate term by term:
   \[
   M_X^{(3)}(t) = t^3 e^{t^2 / 2} + 3t e^{t^2 / 2}.
   \]
Now evaluate \( M_X^{(3)}(t) \) at \( t = 0 \):
\[
M_X^{(3)}(0) = (0^3 + 3 \cdot 0) e^{0} = 0.
\]

Thus:
\[
\mathbb{E}[X^3] = M_X^{(3)}(0) = 0.
\]

Hence, the difference simplifies to:
\[
\left| \mathbb{E}[Z_n^3] - \mathbb{E}[N^3] \right| = \left| \mathbb{E}[Z_n^3] \right| \leq \frac{\sum_{j=1}^n \gamma_j}{s_n^3} = \frac{\Gamma_n}{s_n^3}.
\]

Since \( \mathbb{E}[\mathcal{N}^3] = 0 \), the \eqref{final_eq} simplifies to:
\[
\left| \mathbb{E}[R(Z_n)] - \mathbb{E}[R(\mathcal{N})] \right| \leq \frac{M}{6} \mathbb{E}[Z_n^3].
\]

Substituting \( \mathbb{E}[Z_n^3] \leq \frac{\Gamma_n}{s_n^3} \), we get:
\[
\mathbb{E}[R(Z_n)] \leq \frac{M}{6} \frac{\Gamma_n}{s_n^3}.
\]

Finally, by the assumption:
\[
\frac{\Gamma_n}{s_n^3} \to 0 \quad \text{as } n \to \infty,
\]
it follows that:
\[
\mathbb{E}[f(Z_n)] \to \mathbb{E}[f(\mathcal{N})].

   \newpage


\subsubsection{Informal Proof}
Informal proof of Lyapounov's theorem for a single sequence by the method of Lindeberg \cite{chung2000course}.
\begin{itemize}
    \item \textbf{Notation and Statement}
    \begin{enumerate}
    \item \( \{X_j\}_{j=1}^n \) be a sequence of independent random variables with:
    \begin{itemize}
        \item[] \( \mathbb{E}[X_j] = 0 \), 
        \item[] \( \text{Var}(X_j) = \sigma_j^2 \) (finite variances, \( \sigma_j^2 < \infty \)),
        \item[] \( \mathbb{E}[|X_j|^3] = \gamma_j \) (finite third moments, \( \gamma_j < \infty \)).
    \end{itemize}

        \item Define:
        \begin{itemize}
            \item[] \( S_n = \sum_{j=1}^n X_j \),
            \item[] \( s_n^2 = \sum_{j=1}^n \sigma_j^2 \) (total variance),
            \item[] \( \Gamma_n = \sum_{j=1}^n \gamma_j \) (total third moment).
        \end{itemize}

        \item Statement:
    If 
    \[
   \frac{\Gamma_n}{s_n^3} \to 0 \quad \text{as } n \to \infty.
   \]
   then 
   \[
   \frac{S_n}{s_n} \xrightarrow{d} \Phi
   \]
   where \( \Phi\) denotes the standard normal distribution \( \mathcal{N}(0,1) \).
   
    \end{enumerate}
    \item \textbf{Step-by-Step Proof}
    \begin{enumerate}
        \item \textbf{Normalize the Random Variables}
        
        Define the normalized variables:
\[
X_{n,j} = \frac{X_j}{s_n}, \quad \text{for } j = 1, \dots, n.
\]
The sum \( S_n \) is now expressed as:
\[
\frac{S_n}{s_n} = \sum_{j=1}^n X_{n,j}.
\]

\item \textbf{Use the Lindeberg Replacement to approximate}

Replace each \( X_j \) with a corresponding normal random variable \( Y_j \sim \mathcal{N}(0, \sigma_j^2) \), where \( \{Y_j\}_{j=1}^n \) are independent and have the same mean and variance as \( X_j \), then satisfy:
\[
\mathbb{E}[Y_j] = 0 \quad \text{and} \quad \text{Var}(Y_j) = \sigma_j^2.
\]

Let all the \( X\)'s and \( Y\)'s be totally independent. 

Since  \( Y_j \sim \mathcal{N}(0, \sigma_j^2) \), the normalized random variable:
\[
\frac{Y_j}{s_n} \sim \mathcal{N}\left(0, \frac{\sigma_j^2}{s_n^2}\right).
\]

Adding these normalized variables gives:
\[
\frac{1}{s_n} \sum_{j=1}^n Y_j \sim \mathcal{N}\left(0, \sum_{j=1}^n \frac{\sigma_j^2}{s_n^2}\right).
\]

Since \( s_n^2 = \sum_{j=1}^n \sigma_j^2 \), this simplifies to:
\[
\frac{1}{s_n} \sum_{j=1}^n Y_j \sim \mathcal{N}(0, 1).
\]

Now, construct the sequence \( Z\):
\[
Z_j = Y_1 + \dots + Y_{j-1} + X_{j + 1} + \dots + X_n, \quad 1 \leq j \leq n.
\]
Thus:
\begin{itemize}
    \item[] \( Z_1 = X_2 + X_3 + \dots + X_n \),
    \item[] \( Z_2 = Y_1 + X_3 + \dots + X_n \),
    \item[] \( Z_n = Y_1 + Y_2 + \dots + Y_{n-1} \).
\end{itemize}

In general, each \( Z_j \) represents a sum where:
\begin{itemize}
    \item All variables before \( X_j \) are replaced by \( Y_1, \dots, Y_{j-1} \),
    \item \( X_j \) is excluded from the summation,
    \item All variables after \( X_j \) remain as \( X_{j+1}, X_{j+2}, \dots, X_n \).
\end{itemize}

Thus, by telescoping property, we have:
\[
Y_j + Z_j = X_{j+1} + Z_{j+1}.
\]

\item \textbf{Compare Distributions}

To show that \( \frac{S_n}{s_n} \xrightarrow{d} \mathcal{N}(0, 1) \), we compare their expectations. 

\textbf{Using Test Funtions}

Consider a test function \( f \) from \( C^3_B \), the class of bounded continuous functions with three bounded derivatives.

Consider:
\[
\mathbb{E}\left[f\left(\frac{S_n}{s_n}\right)\right] \quad \text{and} \quad \mathbb{E}\left[f\left(\mathcal{N}\right)\right],
\]

By introducing the replacement sequence \( Z_j \), we rewrite:

\[
\mathbb{E}\left[f\left(\frac{S_n}{s_n}\right)\right] - \mathbb{E}\left[f\left(\frac{Z_n}{s_n}\right)\right].
\]

By telescoping:
\[
\mathbb{E}\left[f\left(\frac{S_n}{s_n}\right)\right] - \mathbb{E}\left[f\left(\frac{Z_n}{s_n}\right)\right].
\]

\[
= \mathbb{E}\left[f\left(\frac{X_1 + \cdots + X_n}{s_n}\right)\right] - \mathbb{E}\left[f\left(\frac{Y_1 + \cdots + Y_n}{s_n}\right)\right].
\]

\[
= \sum_{j=1}^n \left[\mathbb{E}\left[f\left(\frac{X_j + Z_j}{s_n}\right)\right] - \mathbb{E}\left[f\left(\frac{Y_j + Z_j}{s_n}\right)\right]\right].
\]

\item \textbf{Expand expectations with Taylor’s theorem}

By Taylor's theorem for \( f \in C^3_B \):
\[
\left|f(x + y) - \left[f(x) + f'(x)y + \frac{f''(x)}{2}y^2\right]\right| \leq \frac{M}{6}|y|^3,
\]
where \( M = \sup_{x \in \mathbb{R}} |f^{(3)}(x)| \) is the maximum bound on the third derivative of \( f \).

Apply this to \( f(\xi + \eta) \) and take Expectations, we write:
\[
\left| \mathbb{E}[f(\xi + \eta)] - \mathbb{E}[f(\xi)] - \mathbb{E}[f'(\xi)]\mathbb{E}[\eta] - \frac{1}{2}\mathbb{E}[f''(\xi)]\mathbb{E}[\eta^2] \right| \leq \frac{M}{6} \mathbb{E}[|\eta|^3],
\]
where \( \xi \) and \( \eta \) are independent random variables such that \(\mathbb{E}[|\eta|^3] < \infty \).

Then, let \( \zeta \) be another independent random variable, having the same mean and variance as \( \eta \). Now, consider:
     \[
     \mathbb{E}[f(\xi + \eta)] - \mathbb{E}[f(\xi + \zeta)].
     \]
     
Using Taylor's theorem again, this difference can be bounded as:
     \[
     \left| \mathbb{E}[f(\xi + \eta)] - \mathbb{E}[f(\xi + \zeta)] \right| \leq \frac{M}{6} (\mathbb{E}[|\eta|^3] + \mathbb{E}[|\zeta|^3]),
     \]
     where the sum \( \mathbb{E}[|\eta|^3] + \mathbb{E}[|\zeta|^3] \) accounts for the third absolute moments of both random variables.

Then, substitute with:
\begin{itemize}
    \item \( \xi = Z_j / s_n \),
    \item \( \eta = X_j / s_n \),
    \item \( \zeta = Y_j / s_n \).
\end{itemize}
We have:
   \begin{equation} \label{eq:1}
       \left| \mathbb{E}\left[f\left(\frac{Z_j}{s_n} + \frac{X_j}{s_n}\right)\right] - \mathbb{E}\left[f\left(\frac{Z_j}{s_n} + \frac{Y_j}{s_n}\right)\right] \right| \leq \frac{M}{6} \left( \mathbb{E}\left[\left| \frac{X_j}{s_n} \right|^3\right] + \mathbb{E}\left[\left| \frac{Y_j}{s_n} \right|^3\right] \right).
   \end{equation}
   
\item \textbf{Bound error terms using Big-O notation}

From the definition of \( X_j / s_n \) and \( Y_j / s_n \), we know:
     \[
     \mathbb{E}\left[\left|\frac{X_j}{s_n}\right|^3\right] = \frac{\mathbb{E}[|X_j|^3]}{s_n^3}, \quad \mathbb{E}\left[\left|\frac{Y_j}{s_n}\right|^3\right] = \frac{\mathbb{E}[|Y_j|^3]}{s_n^3}.
     \]

For \( Y_j \sim \mathcal{N}(0, \sigma_j^2) \), the third absolute moment is:
     \[
     \mathbb{E}[|Y_j|^3] = c \sigma_j^3,
     \]
     where \( c = \sqrt{8 / \pi} \) (a constant depending on the normal distribution).

Since \( \mathbb{E}[|X_j|^3] = \gamma_j \) and \(\mathbb{E}[|Y_j|^3] = c \sigma_j^3\), we wrire:
     \[
   \mathbb{E}\left[\left|\frac{X_j}{s_n}\right|^3\right] + \mathbb{E}\left[\left|\frac{Y_j}{s_n}\right|^3\right] = \frac{\gamma_j}{s_n^3} + \frac{c \sigma_j^3}{s_n^3}.
   \]

By summing over \(j = 1, \dots , n\), \eqref{eq:1} becomes:
\[
\sum_{j=1}^n \left| \mathbb{E}\left[f\left(\frac{Z_j}{s_n} + \frac{X_j}{s_n}\right)\right] - \mathbb{E}\left[f\left(\frac{Z_j}{s_n} + \frac{Y_j}{s_n}\right)\right] \right| \leq \frac{M}{6} \sum_{j=1}^n \left( \frac{\gamma_j}{s_n^3} + \frac{c \sigma_j^3}{s_n^3} \right).
\]

Lyapunov's inequality states that:
\[
\sigma_j^3 \leq \gamma_j.
\]
Thus:
\[
\frac{\gamma_j}{s_n^3} + \frac{c \cdot \sigma_j^3}{s_n^3} \leq \frac{\gamma_j}{s_n^3} + \frac{c \cdot \gamma_j}{s_n^3} = \frac{(1 + c) \cdot \gamma_j}{s_n^3}.
\]
Simplify the Sum, we have:

\begin{equation} \label{eq:2}
\frac{M}{6} \sum_{j=1}^n \left( \frac{\gamma_j}{s_n^3} + \frac{c \cdot \sigma_j^3}{s_n^3} \right) \leq \frac{M}{6} \cdot \frac{1}{s_n^3} \sum_{j=1}^n (1 + c) \gamma_j.
\end{equation}

Let \( K = \frac{M}{6}(1 + c) \), and the total third absolute moment of \( X_j \):
\[
\Gamma_n = \sum_{j=1}^n \gamma_j ( \space as \space define \space above).
\]
We substitute these into the inequality \eqref{eq:2}:
\begin{equation} \label{eq:3}
\frac{M}{6} \sum_{j=1}^n \left( \frac{\gamma_j}{s_n^3} + \frac{c \cdot \sigma_j^3}{s_n^3} \right) \leq K \cdot \frac{\Gamma_n}{s_n^3}.
\end{equation}

By the definition of Big-O Notation, we have 
\begin{displayquote}
For a function \( f(n) \), we say that \( f(n) = O(g(n)) \) if there exist positive constants \( C > 0 \) and \( n_0 \geq 1 \) such that:
\[
|f(n)| \leq C |g(n)|, \quad \text{for all } n \geq n_0.
\]
\end{displayquote}

Here:
\begin{itemize}
    \item \( f(n) = \frac{\Gamma_n}{s_n^3} \),
    \item \( g(n) = \frac{\Gamma_n}{s_n^3} \).
\end{itemize}

Clearly:
\[
|f(n)| = \left| \frac{\Gamma_n}{s_n^3} \right| \quad \text{and} \quad |g(n)| = \left| \frac{\Gamma_n}{s_n^3} \right|.
\]

Since \( f(n) \) and \( g(n) \) are identical, we have:
\[
|f(n)| \leq 1 \cdot |g(n)| \quad \text{for all } n \geq 1.
\]


Here, the constant \( C = 1 \). Then, the inequality \( |f(n)| \leq C |g(n)| \) holds for all \( n \geq 1 \), so we can choose \( n_0 = 1 \).

Since we have found constants \( C = 1 \) and \( n_0 = 1 \) such that:
\[
|f(n)| \leq C |g(n)| \quad \text{for all } n \geq n_0,
\]
it follows by the definition of Big-O notation that:
\begin{equation} \label{eq:4}
\frac{\Gamma_n}{s_n^3} = O\left(\frac{\Gamma_n}{s_n^3}\right).
\end{equation}

The Big O Notation property called \textbf{Multiplication by a constant} states that:
Let \( k \) be a nonzero constant. Then:
\[
O(|k| \cdot g) = O(g)
\]
Apply this to \eqref{eq:4}, we have:
   \[
   K \cdot \frac{\Gamma_n}{s_n^3} = O\left(\frac{\Gamma_n}{s_n^3}\right).
   \]
Then \eqref{eq:3} becomes:
\[
\frac{M}{6} \sum_{j=1}^n \left( \frac{\gamma_j}{s_n^3} + \frac{c \cdot \sigma_j^3}{s_n^3} \right) \leq O\left(\frac{\Gamma_n}{s_n^3}\right).
\]

We have thus obtained the following estimate:
\[
\forall f \in C^3: \left| \space  \mathbb{E}\left[f\left(\frac{S_n}{s_n}\right)\right] - \mathbb{E}\left[f\left(N\right)\right] \right| \leq O\left(\frac{\Gamma_n}{s_n^3}\right).
\]

\item \textbf{Convergence to Normal}

By Lyapunov's condition:
\[
\frac{\Gamma_n}{s_n^3} \to 0 \quad \text{as } n \to \infty.
\]
This directly implies that:
\[
\left| \mathbb{E}\left[f\left(\frac{S_n}{s_n}\right)\right] - \mathbb{E}\left[f(N)\right] \right| \to 0.
\]

Since \( \mathbb{E}[f(S_n / s_n)] \to \mathbb{E}[f(N)] \) for all bounded and continuous test functions \( f \), by the general criterion for vague convergence (in Theorem 6.1.6 in \cite{chung2000course}), we conclude that:
\[
\frac{S_n}{s_n} \xrightarrow{d} \mathcal{N}(0, 1).
\]

    \end{enumerate}
\end{itemize}
